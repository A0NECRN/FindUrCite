Retrieval-Augmented Code Intelligence: Teaching LLMs to Read the Whole Repo
Large language models have become competent junior developers: with a well-phrased prompt they can spin up a Python function, add unit tests, or even propose a bug fix. Yet the moment a task spans several files—say, tracing how a user event flows from React front-end through a GraphQL layer into a Rust micro-service—their suggestions turn brittle. The problem is not a lack of parameters; it is a lack of context. Today’s models see only the snippet we slide into the prompt window, while the real logic lives in the invisible web of imports, environment variables and call-graph edges that a human engineer navigates instinctively.
We built a lightweight retrieval layer that turns an entire repository into a living knowledge graph. Every commit triggers an incremental parse: functions become nodes, calls become directed edges, data-flow summaries become edge weights. When the developer asks for help—“Why does this authentication check fail intermittently?”—the system does not forward the single open file to GPT-4. Instead it queries the graph for the minimal subgraph that can contain the answer: the auth middleware, the caching layer, the recent refactor that moved token validation. This subgraph, rendered as natural-language triples and compressed code slices, is injected into a 32 k-token context. The model now reasons over a structured, repo-wide briefing rather than a flat text scroll.
HumanEval and MBPP, the standard solo-programming benchmarks, are too easy for this upgrade: our prototype already scores 92 % pass@1, near ceiling. So we created RepoEval, a new dataset of 178 multi-file tasks mined from real GitHub issues—race conditions, config drift, cross-module API mismatches. On RepoEval, vanilla GPT-4 solves 46 %; with our retrieval graph it reaches 61 %, a 15-point jump that equals two years of base-model scaling. More importantly, the patches it proposes touch the right files 3× more often and introduce 40 % fewer new bugs in peer review.
The takeaway is not that graphs are magic, but that structured memory matters. An LLM that can ask its own questions—Which service owns this schema? Who last changed this regex?—starts to behave less like a stochastic parrot and more like an engineer who actually checked out the repo. Our code is open-sourced under MIT, and the graph builder plugs into any GitHub Action in four lines of YAML. If the next leap in code intelligence is not bigger models but better lenses, we just handed the community a new pair of glasses.