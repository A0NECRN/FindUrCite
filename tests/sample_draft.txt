Recent advances in large language models (LLMs) have demonstrated significant potential in software engineering tasks, particularly in automated code generation and review. However, existing methods often struggle with complex, multi-file dependencies and subtle logic errors that require deep semantic understanding. This paper proposes a novel retrieval-augmented generation (RAG) framework that enhances LLMs with a dynamic knowledge graph of the codebase. By mapping function call relationships and data flow into a graph structure, our system allows the LLM to query relevant context beyond the immediate file scope. We evaluate our approach on the HumanEval and MBPP benchmarks, showing a 15% improvement in pass@1 rate compared to standard GPT-4 baselines. Our findings suggest that structured context retrieval is key to unlocking the next level of code intelligence.
