import os
import sys
import argparse
from searcher import Searcher
from analyzer import Analyzer
from code_finder import CodeFinder
import time
from pdf_processor import PDFProcessor
import concurrent.futures

def generate_report(user_input, results, output_dir, filename="research_result.md"):
    report_path = os.path.join(output_dir, filename)
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(f"# Research Report: {user_input}\n\n")
        
        # Disclaimer
        f.write("> **Disclaimer**: This report is generated by an AI system (FindUrCite). "
                "The analysis is based on available paper content (Abstract or Full Text). "
                "Full text analysis is performed for highly relevant papers with accessible PDFs. "
                "Please verify with the original papers.\n\n")

        # Table Header based on Excel Format (22 columns)
        headers = [
            "序号", "竞品/关键 paper 题目", "年份", "等级\n(1-5，5最优)", "契合度分析", "关键词", 
            "发表期刊/会议，等级", "作者信息", "单位信息", "细分领域", "链接", "PDF",
            "解决了什么问题 + 问题数学定义", 
            "解决了什么瓶颈问题？用的什么方法？", 
            "方法关键词", "算法流程\n(建议使用伪代码)", 
            "实验设置\n(数据集, 优越性, 对比方法...)", 
            "缺陷\n(为我们工作入场铺路)", 
            "阅读者评价\n(改进点, 文章缺陷, 复现难度等)", 
            "代码仓库链接",
            "数据集", "其他", "原文佐证 (Evidence)"
        ]
        
        f.write("| " + " | ".join([h.replace('\n', '<br>') for h in headers]) + " |\n")
        f.write("| " + " | ".join(["---"] * len(headers)) + " |\n")
        
        for i, item in enumerate(results):
            p = item['paper']
            a = item.get('analysis', {})
            c = item.get('codes', [])
            
            # Format Authors
            authors_str = ", ".join(p.get('authors', [])[:3])
            if len(p.get('authors', [])) > 3:
                authors_str += " et al."
            
            # Institutions
            inst_str = "Not available"
            if p.get('affiliations'):
                inst_str = ", ".join(p.get('affiliations')[:2])
            
            # PDF Link
            pdf_link = "None"
            pdf_url = None
            if p.get('openAccessPdf'):
                pdf_url = p.get('openAccessPdf', {}).get('url')
                pdf_link = f"[PDF]({pdf_url})"
            elif p.get('url') and "arxiv.org" in p.get('url'):
                 pdf_link = f"[PDF]({p.get('url').replace('abs', 'pdf')})"

            # Format Code
            code_str = "None"
            if c:
                top_code = c[0]
                code_str = f"[{top_code['repo_name']}]({top_code['url']}) (⭐{top_code['stars']})"

            # Clean text
            def clean(text):
                if not isinstance(text, str): return str(text)
                return text.replace("\n", "<br>").replace("|", "\|")
            
            # Evidence formatting
            evidence = a.get('evidence_quotes', [])
            if isinstance(evidence, list):
                evidence_str = "<br>".join([f"- {e}" for e in evidence])
            else:
                evidence_str = str(evidence)

            row = [
                str(i + 1),
                clean(p.get('title', 'N/A')),
                str(p.get('year', 'N/A')),
                str(a.get('relevance_score', 0)),
                clean(a.get('match_reasoning', 'N/A')),
                clean(", ".join(p.get('keywords', [])[:3]) if p.get('keywords') else "N/A"),
                clean(p.get('venue', 'N/A')), 
                clean(authors_str),
                clean(inst_str),
                clean(a.get('sub_field', 'N/A')),
                f"[Link]({p.get('url', '#')})",
                pdf_link,
                clean(a.get('problem_def', 'N/A')),
                clean(a.get('methodology', 'N/A')),
                clean(a.get('method_keywords', 'N/A')),
                clean(a.get('algorithm_summary', 'N/A')),
                clean(a.get('experiments', 'N/A')),
                clean(a.get('limitations', 'N/A')),
                clean(a.get('critique', 'N/A')),
                code_str,
                clean(a.get('datasets', 'N/A')),
                clean(a.get('others', 'N/A')),
                clean(evidence_str)
            ]
            
            f.write("| " + " | ".join(row) + " |\n")
    
    print(f"[Main] Report generated: {filename}")

def main():
    parser = argparse.ArgumentParser(description="FindUrCite - AI Research Assistant")
    parser.add_argument("input", help="Your research idea, draft text, or path to a text file (.txt)")
    parser.add_argument("--model", default="qwen2.5:7b", help="Ollama model to use")
    parser.add_argument("--output", default="research_result.md", help="Output filename")
    args = parser.parse_args()

    # Handle file input
    user_text = args.input
    if os.path.exists(args.input) and os.path.isfile(args.input):
        try:
            with open(args.input, 'r', encoding='utf-8') as f:
                user_text = f.read()
            print(f"[Main] Loaded text from file: {args.input} ({len(user_text)} chars)")
        except Exception as e:
            print(f"[Main] Error reading file: {e}")
            return

    print(f"Initializing modules with model: {args.model}...")
    
    try:
        analyzer = Analyzer(model=args.model)
        searcher = Searcher()
        code_finder = CodeFinder()
        pdf_processor = PDFProcessor()
    except Exception as e:
        print(f"Initialization failed: {e}")
        return

    # Step 1: Analyze User Input (New Logic)
    print("Step 1: Analyzing user input...")
    input_analysis = analyzer.analyze_user_input(user_text)
    
    core_contribution = input_analysis.get('core_contribution', 'N/A')
    # Support both new 'search_queries' and old 'search_keywords' for backward compatibility
    search_queries = input_analysis.get('search_queries', [])
    if not search_queries:
        keywords = input_analysis.get('search_keywords', [])
        if keywords:
            search_queries = [" ".join(keywords[:4])]
        else:
            search_queries = [user_text[:50]]
            
    key_viewpoint = input_analysis.get('key_viewpoint', user_text[:100])
    
    print(f"  - Core Contribution: {core_contribution}")
    print(f"  - Generated Search Queries: {search_queries}")
    print(f"  - Key Viewpoint: {key_viewpoint}")
    
    # Step 2: Search Papers
    print("Step 2: Searching papers (Expanded Scope)...")
    # Using search_multiple_queries with higher limit (5 per source * 2 sources * 3 queries ~ 30 papers max)
    papers = searcher.search_multiple_queries(search_queries, limit_per_source=5)
    
    if not papers:
        print("No papers found.")
        return

    # Step 3: Find Code (Parallel)
    print("Step 3: Finding code (Parallel)...")
    paper_titles = [p['title'] for p in papers]
    code_results = code_finder.find_codes_parallel(paper_titles)

    # Step 4: Analyze Papers (Deep Read Pipeline)
    print("Step 4: Analyzing papers (Deep Read Pipeline)...")
    
    # Create workspace folder early to store PDFs
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    workspace_name = f"research_output_{timestamp}"
    workspace_path = os.path.join(os.getcwd(), workspace_name)
    if not os.path.exists(workspace_path):
        os.makedirs(workspace_path)
    
    # Configure PDF processor to use workspace
    pdf_processor.set_download_dir(os.path.join(workspace_path, "pdfs"))
    
    final_results = []
    
    # 4a. Phase 1: Abstract Analysis (Sequential/Fast)
    print("  -> Phase 1: Screening Abstracts...")
    candidates_for_deep_read = []
    
    for i, paper in enumerate(papers):
        print(f"    [{i+1}/{len(papers)}] Screening: {paper['title'][:30]}...")
        analysis = analyzer.analyze_paper_details(key_viewpoint, paper)
        relevance = analysis.get('relevance_score', 0)
        
        item = {
            'paper': paper,
            'analysis': analysis,
            'codes': code_results.get(paper['title'], [])
        }
        
        if relevance >= 4:
             candidates_for_deep_read.append(item)
        else:
             final_results.append(item)

    # 4b. Phase 2: Parallel PDF Download & Text Extraction
    print(f"  -> Phase 2: Deep Reading {len(candidates_for_deep_read)} candidates (Parallel IO)...")
    
    def process_pdf_candidate(item):
        paper = item['paper']
        pdf_url = None
        if paper.get('openAccessPdf'):
            pdf_url = paper.get('openAccessPdf', {}).get('url')
        elif paper.get('url') and "arxiv.org/abs" in paper.get('url'):
            pdf_url = paper.get('url').replace('abs', 'pdf')
            
        full_text = None
        if pdf_url:
            try:
                # Use a thread-safe print or just let it interleave
                # print(f"      -> Downloading: {paper['title'][:20]}...") 
                pdf_path = pdf_processor.download_pdf(pdf_url)
                if pdf_path:
                    full_text = pdf_processor.extract_text(pdf_path, max_pages=15)
            except Exception as e:
                print(f"      -> Error processing {paper['title'][:20]}: {e}")
        
        return item, full_text

    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        future_to_item = {executor.submit(process_pdf_candidate, item): item for item in candidates_for_deep_read}
        
        processed_candidates = []
        for future in concurrent.futures.as_completed(future_to_item):
            item, text = future.result()
            if text and len(text) > 1000:
                item['full_text'] = text
                print(f"      -> Extracted {len(text)} chars for: {item['paper']['title'][:30]}")
            else:
                print(f"      -> Failed to extract text for: {item['paper']['title'][:30]}")
            processed_candidates.append(item)

    # 4c. Phase 3: Full Text Analysis (Sequential LLM)
    print("  -> Phase 3: Analyzing Full Texts with LLM...")
    for item in processed_candidates:
        if 'full_text' in item:
            print(f"    -> Analyzing Full Text: {item['paper']['title'][:30]}...")
            full_analysis = analyzer.analyze_full_paper(key_viewpoint, item['paper'], item['full_text'])
            item['analysis'] = full_analysis # Update with better analysis
        final_results.append(item)


    # Sort by relevance score
    final_results.sort(key=lambda x: x['analysis'].get('relevance_score', 0), reverse=True)

    # Step 5: Generate Report
    # Pass the Core Contribution as the "User Input" context for the report
    report_context = f"**Draft Analysis:** {core_contribution}\n\n**Viewpoint:** {key_viewpoint}"
    
    generate_report(report_context, final_results, workspace_path, args.output)
    
    print(f"[Main] All artifacts (report and PDFs) are saved in: {workspace_path}")

if __name__ == "__main__":
    main()
